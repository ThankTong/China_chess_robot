import os
import cv2
import time
import threading
import queue
import numpy as np
import torch
from ultralytics import YOLO
import ctypes

# ==========================================
# 1. C·∫§U H√åNH
# ==========================================
DISPLAY_SCALE = 1.5         # Zoom khung h√¨nh hi·ªÉn th·ªã
TARGET_WIDTH = 320          # Resize ·∫£nh nh·ªè ƒë·ªÉ AI ch·∫°y nhanh
CONF = 0.5
IOU = 0.45
# ƒê∆∞·ªùng d·∫´n model c·ªßa b·∫°n
MODEL_PATH = r"D:\xiangqi_robot_TrainningAI_Final_4\models_chinesechess1\content\runs\detect\train\weights\best.pt"

# ==========================================
# 2. H√ÄM H·ªñ TR·ª¢ T√åM CAMERA (ƒê∆∞a l√™n ƒë·∫ßu)
# ==========================================
def find_external_opencv_index(max_idx=4):
    """Qu√©t t√¨m camera (∆∞u ti√™n camera ngo√†i, index kh√°c 0)"""
    print("üîÑ ƒêang qu√©t t√¨m Camera...")
    good_cam = 0
    for i in range(max_idx):
        cap = cv2.VideoCapture(i, cv2.CAP_DSHOW)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                print(f"   - T√¨m th·∫•y Camera index {i}")
                # ∆Øu ti√™n l·∫•y camera kh√¥ng ph·∫£i 0 (th∆∞·ªùng 0 l√† webcam laptop)
                if i > 0: 
                    good_cam = i
                    cap.release()
                    break 
            cap.release()
    return good_cam

# ==========================================
# 3. KH·ªûI T·∫†O CAMERA & DEVICE
# ==========================================
# Ch·ªçn Device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print("üöÄ Using device:", DEVICE)

# X·ª≠ l√Ω ch·ªçn Camera (Logic RealSense ho·∫∑c OpenCV)
use_realsense = False
pipeline = None
cap = None

# Ki·ªÉm tra RealSense tr∆∞·ªõc (N·∫øu b·∫°n c√≥ c√†i th∆∞ vi·ªán v√† c·∫Øm thi·∫øt b·ªã)
try:
    import pyrealsense2 as rs
    ctx = rs.context()
    if len(ctx.query_devices()) > 0:
        print("üì∑ Ph√°t hi·ªán RealSense! ƒêang kh·ªüi t·∫°o...")
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        pipeline.start(config)
        use_realsense = True
        print("‚úÖ RealSense ƒë√£ s·∫µn s√†ng.")
except:
    use_realsense = False

# N·∫øu kh√¥ng c√≥ RealSense th√¨ d√πng OpenCV
if not use_realsense:
    # ∆Øu ti√™n l·∫•y t·ª´ bi·∫øn m√¥i tr∆∞·ªùng, n·∫øu kh√¥ng th√¨ t·ª± qu√©t
    env_idx = os.environ.get("VIDEO_INDEX")
    if env_idx:
        vid_idx = int(env_idx)
    else:
        vid_idx = find_external_opencv_index()
    
    print(f"üì∑ ƒêang m·ªü Camera OpenCV Index: {vid_idx}")
    cap = cv2.VideoCapture(vid_idx, cv2.CAP_DSHOW)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# ==========================================
# 4. LOAD MODEL
# ==========================================
print("üß† ƒêang load Model YOLO...")
try:
    model = YOLO(MODEL_PATH)
    if DEVICE == "cuda":
        model.to(DEVICE)
        try: model.model.half() # TƒÉng t·ªëc b·∫±ng FP16
        except: pass
except Exception as e:
    print(f"‚ùå L·ªói load model: {e}")
    # N·∫øu l·ªói ƒë∆∞·ªùng d·∫´n th√¨ load model chu·∫©n ƒë·ªÉ test t·∫°m
    print("‚ö†Ô∏è ƒêang load yolov8n.pt ƒë·ªÉ test t·∫°m...")
    model = YOLO("yolov8n.pt")

# ==========================================
# 5. MULTI-THREADING CAPTURE
# ==========================================
frame_q = queue.Queue(maxsize=1)
stop_event = threading.Event()

def capture_thread():
    """Lu·ªìng ƒë·ªçc camera ri√™ng bi·ªát ƒë·ªÉ tƒÉng FPS"""
    global cap, pipeline
    while not stop_event.is_set():
        frm = None
        if use_realsense:
            try:
                frames = pipeline.wait_for_frames(timeout_ms=1000)
                color_frame = frames.get_color_frame()
                if color_frame:
                    frm = np.asanyarray(color_frame.get_data())
            except: pass
        else:
            if cap and cap.isOpened():
                ret, img = cap.read()
                if ret: frm = img
            else:
                time.sleep(0.1) # Ch·ªù n·∫øu m·∫•t k·∫øt n·ªëi
        
        if frm is not None:
            # Ch·ªâ gi·ªØ frame m·ªõi nh·∫•t
            if not frame_q.empty():
                try: frame_q.get_nowait()
                except: pass
            frame_q.put(frm)
        else:
            time.sleep(0.01)
    
    # Cleanup
    if use_realsense and pipeline: pipeline.stop()
    if cap: cap.release()

# B·∫Øt ƒë·∫ßu lu·ªìng
t = threading.Thread(target=capture_thread, daemon=True)
t.start()

# ==========================================
# 6. V√íNG L·∫∂P CH√çNH (MAIN LOOP)
# ==========================================
cv2.namedWindow("YOLOv8 Inference", cv2.WINDOW_NORMAL)

# L·∫•y k√≠ch th∆∞·ªõc m√†n h√¨nh ƒë·ªÉ ch·ªânh c·ª≠a s·ªï
try:
    user32 = ctypes.windll.user32
    screen_w, screen_h = user32.GetSystemMetrics(0), user32.GetSystemMetrics(1)
except: screen_w, screen_h = 1366, 768

initial_w = min(int(TARGET_WIDTH * DISPLAY_SCALE), screen_w - 100)
initial_h = min(int(480 * DISPLAY_SCALE), screen_h - 100)
cv2.resizeWindow("YOLOv8 Inference", initial_w, initial_h)

prev_time = time.time()
fps = 0.0
alpha_fps = 0.2

print("\n=== ƒêANG CH·∫†Y (B·∫•m 'Q' ƒë·ªÉ tho√°t) ===")

try:
    while True:
        # 1. L·∫•y ·∫£nh
        try:
            frame = frame_q.get(timeout=1.0)
        except queue.Empty:
            continue

        # 2. Resize ƒë·∫ßu v√†o cho AI (gi·ªØ nguy√™n t·ªâ l·ªá)
        h, w = frame.shape[:2]
        scale = TARGET_WIDTH / float(w)
        inp = cv2.resize(frame, (TARGET_WIDTH, int(h * scale)))

        # 3. Predict
        results = model.predict(inp, conf=CONF, iou=IOU, verbose=False, imgsz=TARGET_WIDTH)

        # 4. V·∫Ω
        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cls_id = int(box.cls[0])
                name = model.names.get(cls_id, str(cls_id))
                conf_score = float(box.conf[0])
                
                # M√†u: ƒê·ªè (Red) ho·∫∑c Xanh (Black) - Gi·∫£ s·ª≠ t√™n c√≥ 'r_' l√† ƒë·ªè
                color = (0, 0, 255) if "r_" in name else (0, 255, 0)
                cv2.rectangle(inp, (x1, y1), (x2, y2), color, 2)
                cv2.putText(inp, f"{name} {conf_score:.2f}", (x1, y1 - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

        # 5. FPS
        curr_time = time.time()
        fps = fps * (1 - alpha_fps) + (1.0 / (curr_time - prev_time)) * alpha_fps
        prev_time = curr_time
        cv2.putText(inp, f"FPS: {fps:.1f}", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)

        # 6. Hi·ªÉn th·ªã (Zoom to)
        disp = cv2.resize(inp, (int(inp.shape[1]*DISPLAY_SCALE), int(inp.shape[0]*DISPLAY_SCALE)))
        cv2.imshow("YOLOv8 Inference", disp)

        if cv2.waitKey(1) == ord('q'):
            break

except KeyboardInterrupt: pass
finally:
    stop_event.set()
    t.join()
    cv2.destroyAllWindows()